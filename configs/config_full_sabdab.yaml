data:
  raw_dir: data/raw
  processed_dir: data/processed
  processed_file: processed_data.h5
  splits_dir: data/raw_splits
  manifest_file: data/full_sabdab_train_esm_density_with_clipping.csv
  feature_transform: true
  feature_centering: true
  batch_size_per_gpu: 16 #8 max batch for sum aggregators #6 max batch for concat_stats aggregator #4 max batch for attn_pool aggregator
  num_workers: 20
  samples_per_complex: 10
  use_interchain_ca_distances: true
  use_interchain_pae: true
  use_esm_embeddings: true
  esm_embedding_dim: 320
  use_distance_cutoff: true  # Enable filtering of residue pairs by distance
  distance_cutoff: 12.0  # Maximum CA distance in Angstroms (only used if use_distance_cutoff is true)
  # HDF5 file caching optimization
  use_file_cache: true  # Keep HDF5 files open for faster access
  cache_size_mb: 2048  # HDF5 chunk cache size in MB per file
  max_cached_files: 150  # Maximum number of HDF5 files to keep open simultaneously per worker

model:
  input_dim: 4
  aggregator: concat_stats_by_set_size
  phi_hidden_dims: [128, 32, 64]
  rho_hidden_dims: [256, 256, 256]

training:
  adaptive_weight: true
  epochs: 250
  lr: !!float 5e-3
  weight_decay: !!float 1e-5
  smooth_l1_beta: 0.5
  weighted_loss: true
  bucket_balance: false
  num_buckets: 4
  seed: 42
  lr_scheduler_type: "OneCycleLR"  # or "ReduceLROnPlateau" or "WarmupHoldLinear"
  add_ranking_loss: true      # Whether to add the ranking loss
  add_distance_preservation_loss: true
  ranking_loss_type: "one_minus_rho"  # "fisher" or "one_minus_rho"
  distance_loss_start_epoch: 1
  distance_lambda_start: 1.0
  distance_lambda_min: 0.2
  distance_lambda_max: 10.0
