data:
  raw_dir: data/raw
  processed_dir: data/processed
  processed_file: processed_data.h5
  splits_dir: data/raw_splits
  manifest_file: data/manifest_new_filtered_pae_centered_density_with_clipping_500k_maxlen.csv
  feature_transform: true
  feature_centering: true
  batch_size: 4 #8 max batch for sum aggregators #6 max batch for concat_stats aggregator #4 max batch for attn_pool aggregator
  num_workers: 4
  samples_per_complex: 3

model:
  input_dim: 4
  aggregator: concat_stats_by_set_size
  phi_hidden_dims: [128, 32, 64]
  rho_hidden_dims: [256, 256, 256]

training:
  adaptive_weight: true
  epochs: 150
  lr: !!float 1e-3
  weight_decay: !!float 1e-5
  smooth_l1_beta: 0.5
  weighted_loss: true
  bucket_balance: false
  num_buckets: 4
  seed: 42
  lr_scheduler_type: "OneCycleLR"  # or "ReduceLROnPlateau"
  lr_scheduler_factor: 0.75
  lr_scheduler_patience: 5
  min_lr: !!float 1e-5
  onecycle_max_lr: !!float 1e-3         # Only used if lr_scheduler_type is OneCycleLR
  onecycle_pct_start: 0.3       # Only used if lr_scheduler_type is OneCycleLR
  onecycle_div_factor: 10.0     # Only used if lr_scheduler_type is OneCycleLR
  onecycle_final_div_factor: !!float 1000 # Only used if lr_scheduler_type is OneCycleLR
  add_ranking_loss: true      # Whether to add the ranking loss
  spearman_tau: 0.02          # tau for the soft spearman rank loss
  ranking_loss_weight: 0.75   # lambda for the ranking loss
  lambda_ema_alpha: 0.75    # Smoothing factor for dynamic lambda (0.0 means no smoothing, 1.0 means lambda never changes from initial)
